# -*- coding: utf-8 -*-
"""
AIè¯­éŸ³è¯†åˆ«æ¨¡å—
æ”¯æŒå¤šç§AIè¯­éŸ³è¯†åˆ«å¼•æ“ï¼šç™¾åº¦ã€Whisperã€Azureç­‰
æ”¯æŒå”¤é†’è¯åŠŸèƒ½ï¼Œé¿å…é¢‘ç¹è°ƒç”¨AIè¯†åˆ«
"""

import speech_recognition as sr
import tempfile
import os
# import whisper
import requests
import base64
from datetime import datetime
from config import SPEECH_CONFIG, AI_SPEECH_CONFIG, WAKE_WORD_CONFIG

class AISpeechRecognizer:
    def __init__(self, status_callback=None):
        """åˆå§‹åŒ–AIè¯­éŸ³è¯†åˆ«å™¨
        
        Args:
            status_callback: çŠ¶æ€å›è°ƒå‡½æ•°ï¼Œç”¨äºæ›´æ–°GUIçŠ¶æ€æ˜¾ç¤º
        """
        try:
            self.recognizer = sr.Recognizer()
            self.microphone = sr.Microphone()
            self.is_listening = False
            self.listen_thread = None
            self.status_callback = status_callback
            self.engine = AI_SPEECH_CONFIG.get('engine', 'baidu')
            
            # å”¤é†’è¯ç›¸å…³å±æ€§
            self.wake_word_enabled = WAKE_WORD_CONFIG.get('enabled', True)
            self.wake_words = WAKE_WORD_CONFIG.get('keywords', ['å°æ™º'])
            self.wake_word_timeout = WAKE_WORD_CONFIG.get('timeout', 3)
            self.command_timeout = WAKE_WORD_CONFIG.get('command_timeout', 10)
            self.wake_sensitivity = WAKE_WORD_CONFIG.get('sensitivity', 0.7)
            
            # é«˜çº§å”¤é†’è¯é…ç½®
            self.fallback_detection = WAKE_WORD_CONFIG.get('fallback_detection', True)
            self.confidence_threshold = WAKE_WORD_CONFIG.get('confidence_threshold', 0.6)
            self.retry_count = WAKE_WORD_CONFIG.get('retry_count', 3)
            self.audio_feedback = WAKE_WORD_CONFIG.get('audio_feedback', True)
            self.adaptive_threshold = WAKE_WORD_CONFIG.get('adaptive_threshold', True)
            self.noise_reduction = WAKE_WORD_CONFIG.get('noise_reduction', True)
            
            # åŠ¨æ€è°ƒæ•´å‚æ•°
            self.dynamic_energy_threshold = WAKE_WORD_CONFIG.get('energy_threshold', 300)
            self.background_noise_samples = []
            self.wake_word_detections = 0
            self.false_positives = 0
            
            # æ›´æ–°çŠ¶æ€
            self._update_status("æ­£åœ¨åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«...")
            
            # è°ƒæ•´éº¦å…‹é£å™ªéŸ³
            self._update_status("æ­£åœ¨è°ƒæ•´éº¦å…‹é£ï¼Œè¯·ä¿æŒå®‰é™...")
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=1)
                # è®¾ç½®èƒ½é‡é˜ˆå€¼
                self.recognizer.energy_threshold = WAKE_WORD_CONFIG.get('energy_threshold', 300)
            
            # åˆå§‹åŒ–AIå¼•æ“
            self._init_ai_engine()
            
            wake_status = "å·²å¯ç”¨" if self.wake_word_enabled else "å·²ç¦ç”¨"
            wake_words_str = "ã€".join(self.wake_words)
            self._update_status(f"è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å®Œæˆï¼Œå”¤é†’è¯åŠŸèƒ½{wake_status}ï¼Œæ”¯æŒå”¤é†’è¯ï¼š{wake_words_str}")
            
        except ModuleNotFoundError as e:
            if "distutils" in str(e):
                error_msg = "éœ€è¦å®‰è£…setuptoolsä»¥å…¼å®¹Python 3.12+"
                self._update_status(f"é”™è¯¯: {error_msg}")
                raise RuntimeError(error_msg) from e
            else:
                raise e
        except Exception as e:
            error_msg = f"è¯­éŸ³è¯†åˆ«æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}"
            self._update_status(f"é”™è¯¯: {error_msg}")
            raise e
    
    def _init_ai_engine(self):
        """åˆå§‹åŒ–AIè¯†åˆ«å¼•æ“"""
        if self.engine == 'baidu':
            self._init_baidu_engine()
        elif self.engine == 'whisper':
            self._init_whisper_engine()
        else:
            self._update_status(f"ä½¿ç”¨é»˜è®¤å¼•æ“: {self.engine}")
    
    def _init_baidu_engine(self):
        """åˆå§‹åŒ–ç™¾åº¦è¯­éŸ³è¯†åˆ«å¼•æ“"""
        config = AI_SPEECH_CONFIG.get('baidu', {})
        self.baidu_app_id = config.get('app_id', '')
        self.baidu_api_key = config.get('api_key', '')
        self.baidu_secret_key = config.get('secret_key', '')
        
        if not all([self.baidu_app_id, self.baidu_api_key, self.baidu_secret_key]):
            self._update_status("è­¦å‘Š: ç™¾åº¦è¯­éŸ³è¯†åˆ«æœªé…ç½®ï¼Œå°†ä½¿ç”¨é»˜è®¤å¼•æ“")
            self.engine = 'google'
        else:
            self._update_status("ç™¾åº¦è¯­éŸ³è¯†åˆ«å¼•æ“å·²é…ç½®")
    
    def _init_whisper_engine(self):
        """åˆå§‹åŒ–Whisperå¼•æ“"""
        try:
            model_size = AI_SPEECH_CONFIG.get('whisper', {}).get('model_size', 'base')
            self.whisper_model = whisper.load_model(model_size) # type: ignore
            self._update_status(f"Whisper {model_size} æ¨¡å‹åŠ è½½å®Œæˆ")
        except ImportError:
            self._update_status("Whisperæœªå®‰è£…ï¼Œå°†ä½¿ç”¨é»˜è®¤å¼•æ“")
            self.engine = 'google'
        except Exception as e:
            self._update_status(f"WhisperåŠ è½½å¤±è´¥: {e}")
            self.engine = 'google'
    
    def _update_status(self, message):
        """æ›´æ–°çŠ¶æ€æ˜¾ç¤º"""
        if self.status_callback:
            self.status_callback(message)
        print(f"[{datetime.now().strftime('%H:%M:%S')}] {message}")
    
    def listen_continuous(self):
        """æŒç»­è¯­éŸ³ç›‘å¬ï¼ˆå•æ¬¡è°ƒç”¨ï¼‰"""
        try:
            self._update_status("ğŸ¤ æ­£åœ¨ç›‘å¬è¯­éŸ³...")
            
            with self.microphone as source:
                # ç›‘å¬éŸ³é¢‘
                audio = self.recognizer.listen(
                    source, 
                    timeout=SPEECH_CONFIG['timeout'],
                    phrase_time_limit=SPEECH_CONFIG['phrase_timeout']
                )
            
            self._update_status("ğŸ”„ æ­£åœ¨è¯†åˆ«è¯­éŸ³...")
            
            # ä½¿ç”¨AIæ¨¡å‹è¯†åˆ«è¯­éŸ³
            text = self._recognize_with_ai(audio)
            
            if text and text.strip(): # type: ignore
                self._update_status(f"âœ… è¯†åˆ«ç»“æœ: {text}")
                return text
            else:
                self._update_status("âš ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³")
                return None
                
        except sr.WaitTimeoutError:
            # è¶…æ—¶ï¼Œæ­£å¸¸æƒ…å†µ
            return None
        except sr.UnknownValueError:
            self._update_status("âš ï¸ è¯­éŸ³ä¸æ¸…æ™°ï¼Œè¯·é‡æ–°è¯´è¯")
            return None
        except sr.RequestError as e:
            self._update_status(f"âŒ è¯†åˆ«æœåŠ¡é”™è¯¯: {e}")
            return None
        except Exception as e:
            self._update_status(f"âŒ è¯†åˆ«å¼‚å¸¸: {e}")
            return None
    
    def recognize_once(self, timeout=5):
        """å•æ¬¡è¯­éŸ³è¯†åˆ«"""
        try:
            self._update_status("ğŸ¤ è¯·å¼€å§‹è¯´è¯...")
            
            with self.microphone as source:
                audio = self.recognizer.listen(source, timeout=timeout, phrase_time_limit=5)
            
            self._update_status("ğŸ”„ æ­£åœ¨ä½¿ç”¨AIæ¨¡å‹è¯†åˆ«...")
            
            # ä½¿ç”¨AIæ¨¡å‹è¯†åˆ«
            text = self._recognize_with_ai(audio)
            
            if text and text.strip(): # type: ignore
                self._update_status(f"âœ… è¯†åˆ«æˆåŠŸ: {text}")
                return text
            else:
                self._update_status("âš ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹")
                return None
                
        except sr.WaitTimeoutError:
            self._update_status("â° ç­‰å¾…è¶…æ—¶ï¼Œæœªæ£€æµ‹åˆ°è¯­éŸ³")
            return None
        except sr.UnknownValueError:
            self._update_status("âš ï¸ æ— æ³•è¯†åˆ«è¯­éŸ³å†…å®¹")
            return None
        except sr.RequestError as e:
            self._update_status(f"âŒ è¯†åˆ«æœåŠ¡é”™è¯¯: {e}")
            return None
        except Exception as e:
            self._update_status(f"âŒ è¯†åˆ«å‡ºé”™: {e}")
            return None
    
    def _recognize_with_ai(self, audio):
        """ä½¿ç”¨AIæ¨¡å‹è¯†åˆ«è¯­éŸ³"""
        if self.engine == 'baidu' and hasattr(self, 'baidu_api_key'):
            return self._recognize_with_baidu(audio)
        elif self.engine == 'whisper' and hasattr(self, 'whisper_model'):
            return self._recognize_with_whisper(audio)
        else:
            # é»˜è®¤ä½¿ç”¨Googleè¯†åˆ«
            return self._recognize_with_google(audio)
    
    def _recognize_with_baidu(self, audio):
        """ä½¿ç”¨ç™¾åº¦AIè¯†åˆ«"""
        try:
            # è·å–è®¿é—®ä»¤ç‰Œ
            token = self._get_baidu_token()
            if not token:
                return self._recognize_with_google(audio)
            
            # è½¬æ¢éŸ³é¢‘æ ¼å¼
            wav_data = audio.get_wav_data()
            
            # è°ƒç”¨ç™¾åº¦API
            url = f"https://vop.baidu.com/server_api"
            headers = {'Content-Type': 'application/json'}
            
            data = {
                'format': 'wav',
                'rate': 16000,
                'channel': 1,
                'cuid': 'python_client',
                'token': token,
                'speech': base64.b64encode(wav_data).decode('utf-8'),
                'len': len(wav_data)
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=10)
            result = response.json()
            
            if result.get('err_no') == 0:
                return result.get('result', [''])[0]
            else:
                self._update_status(f"ç™¾åº¦è¯†åˆ«é”™è¯¯: {result.get('err_msg', 'æœªçŸ¥é”™è¯¯')}")
                return self._recognize_with_google(audio)
                
        except Exception as e:
            self._update_status(f"ç™¾åº¦è¯†åˆ«å¼‚å¸¸: {e}")
            return self._recognize_with_google(audio)
    
    def _get_baidu_token(self):
        """è·å–ç™¾åº¦è®¿é—®ä»¤ç‰Œ"""
        try:
            url = "https://aip.baidubce.com/oauth/2.0/token"
            params = {
                'grant_type': 'client_credentials',
                'client_id': self.baidu_api_key,
                'client_secret': self.baidu_secret_key
            }
            
            response = requests.get(url, params=params, timeout=10)
            result = response.json()
            
            return result.get('access_token')
        except Exception as e:
            self._update_status(f"è·å–ç™¾åº¦ä»¤ç‰Œå¤±è´¥: {e}")
            return None
    
    def _recognize_with_whisper(self, audio):
        """ä½¿ç”¨Whisperæ¨¡å‹è¯†åˆ«"""
        try:
            # ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                tmp_file.write(audio.get_wav_data())
                tmp_path = tmp_file.name
            
            # ä½¿ç”¨Whisperè¯†åˆ«
            result = self.whisper_model.transcribe(tmp_path, language='zh')
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(tmp_path)
            
            return result.get('text', '').strip() # type: ignore
            
        except Exception as e:
            self._update_status(f"Whisperè¯†åˆ«å¼‚å¸¸: {e}")
            return self._recognize_with_google(audio)
    
    def _recognize_with_google(self, audio):
        """ä½¿ç”¨Googleè¯†åˆ«ï¼ˆå¤‡ç”¨ï¼‰"""
        try:
            return self.recognizer.recognize_google(audio, language=SPEECH_CONFIG['language'])
        except Exception as e:
            self._update_status(f"Googleè¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def is_microphone_available(self):
        """æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å¯ç”¨"""
        try:
            with self.microphone as source:
                pass
            return True
        except Exception as e:
            self._update_status(f"éº¦å…‹é£ä¸å¯ç”¨: {e}")
            return False
    
    def listen_with_wake_word(self):
        """å¸¦å”¤é†’è¯çš„æŒç»­ç›‘å¬ï¼ˆå•æ¬¡è°ƒç”¨ï¼‰"""
        if not self.wake_word_enabled:
            # å¦‚æœå”¤é†’è¯æœªå¯ç”¨ï¼Œç›´æ¥è¿›è¡Œæ­£å¸¸è¯†åˆ«
            return self.listen_continuous()
        
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šæ£€æµ‹å”¤é†’è¯
            wake_detected = self._detect_wake_word()
            if not wake_detected:
                return None
            
            # ç¬¬äºŒé˜¶æ®µï¼šè¯†åˆ«å…·ä½“å‘½ä»¤
            self._update_status("ğŸŸ¢ æ£€æµ‹åˆ°å”¤é†’è¯ï¼Œè¯·è¯´å‡ºæ‚¨çš„æŒ‡ä»¤...")
            command = self._listen_for_command()
            return command
            
        except Exception as e:
            self._update_status(f"âŒ å”¤é†’è¯æ£€æµ‹å¼‚å¸¸: {e}")
            return None
    
    def _detect_wake_word(self):
        """æ£€æµ‹å”¤é†’è¯"""
        try:
            self._update_status("ğŸ‘‚ ç­‰å¾…å”¤é†’è¯...")
            
            with self.microphone as source:
                # ç›‘å¬éŸ³é¢‘ï¼Œä½¿ç”¨è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´
                audio = self.recognizer.listen(
                    source, 
                    timeout=self.wake_word_timeout,
                    phrase_time_limit=WAKE_WORD_CONFIG.get('phrase_timeout', 2)
                )
            
            # ä½¿ç”¨è½»é‡çº§è¯†åˆ«æ£€æµ‹å”¤é†’è¯ï¼ˆä½¿ç”¨Googleå¼•æ“ï¼Œé€Ÿåº¦å¿«ï¼‰
            try:
                text = self.recognizer.recognize_google(audio, language=SPEECH_CONFIG['language'])
                if text:
                    self._update_status(f"ğŸ” æ£€æµ‹å†…å®¹: {text}")
                    return self._check_wake_word_match(text)
            except sr.UnknownValueError:
                # æ— æ³•è¯†åˆ«ï¼Œç»§ç»­ç­‰å¾…
                return False
            except sr.RequestError:
                # ç½‘ç»œé”™è¯¯ï¼Œå°è¯•æœ¬åœ°æ£€æµ‹
                return self._simple_wake_word_check(audio) # type: ignore
                
        except sr.WaitTimeoutError:
            # è¶…æ—¶ï¼Œæ­£å¸¸æƒ…å†µ
            return False
        except Exception as e:
            self._update_status(f"âš ï¸ å”¤é†’è¯æ£€æµ‹å‡ºé”™: {e}")
            return False
    
    def _check_wake_word_match(self, text):
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«å”¤é†’è¯"""
        text_lower = text.lower()
        for wake_word in self.wake_words:
            if wake_word.lower() in text_lower:
                self._update_status(f"âœ… æ£€æµ‹åˆ°å”¤é†’è¯: {wake_word}")
                self.wake_word_detections += 1
                self._adaptive_threshold_adjustment(True)
                
                # éŸ³é¢‘åé¦ˆ
                if self.audio_feedback:
                    self._play_wake_word_feedback()
                
                return True
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°å”¤é†’è¯ï¼Œå¯èƒ½æ˜¯è¯¯æ£€
        if len(text_lower) > 0:
            self.false_positives += 1
            self._adaptive_threshold_adjustment(False)
            
        return False
    
    def _adaptive_threshold_adjustment(self, wake_word_detected):
        """è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´"""
        if not self.adaptive_threshold:
            return
            
        try:
            if wake_word_detected:
                # æ£€æµ‹åˆ°å”¤é†’è¯ï¼Œå¯ä»¥é€‚å½“é™ä½é˜ˆå€¼ä»¥æé«˜çµæ•åº¦
                if self.dynamic_energy_threshold > 200:
                    self.dynamic_energy_threshold *= 0.95
            else:
                # è¯¯æ£€ï¼Œæé«˜é˜ˆå€¼ä»¥å‡å°‘è¯¯æŠ¥
                if self.dynamic_energy_threshold < 500:
                    self.dynamic_energy_threshold *= 1.05
            
            # æ›´æ–°è¯†åˆ«å™¨é˜ˆå€¼
            self.recognizer.energy_threshold = self.dynamic_energy_threshold
            
        except Exception as e:
            self._update_status(f"é˜ˆå€¼è°ƒæ•´å‡ºé”™: {e}")
    
    def _play_wake_word_feedback(self):
        """æ’­æ”¾å”¤é†’è¯æ£€æµ‹åé¦ˆéŸ³æ•ˆ"""
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ ç³»ç»Ÿæç¤ºéŸ³æˆ–è‡ªå®šä¹‰éŸ³æ•ˆ
            # ç”±äºé¿å…ä¾èµ–é¢å¤–åº“ï¼Œæš‚æ—¶ä½¿ç”¨ç³»ç»Ÿbeep
            import winsound
            winsound.Beep(800, 200)  # 800Hz, 200ms
        except ImportError:
            # å¦‚æœwinsoundä¸å¯ç”¨ï¼Œè·³è¿‡éŸ³æ•ˆ
            pass
        except Exception:
            # å¿½ç•¥éŸ³æ•ˆæ’­æ”¾é”™è¯¯
            pass
    
    def get_wake_word_stats(self):
        """è·å–å”¤é†’è¯æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'detections': self.wake_word_detections,
            'false_positives': self.false_positives,
            'current_threshold': self.dynamic_energy_threshold,
            'detection_rate': self.wake_word_detections / max(1, self.wake_word_detections + self.false_positives)
        }
    
    def reset_wake_word_stats(self):
        """é‡ç½®å”¤é†’è¯ç»Ÿè®¡"""
        self.wake_word_detections = 0
        self.false_positives = 0
        self.dynamic_energy_threshold = WAKE_WORD_CONFIG.get('energy_threshold', 300)
    
    def _listen_for_command(self):
        """ç›‘å¬ç”¨æˆ·å‘½ä»¤"""
        try:
            with self.microphone as source:
                # ç›‘å¬ç”¨æˆ·å‘½ä»¤ï¼Œä½¿ç”¨è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´
                audio = self.recognizer.listen(
                    source, 
                    timeout=self.command_timeout,
                    phrase_time_limit=8
                )
            
            self._update_status("ğŸ”„ æ­£åœ¨è¯†åˆ«æŒ‡ä»¤...")
            
            # ä½¿ç”¨AIæ¨¡å‹è¯†åˆ«ç”¨æˆ·å‘½ä»¤
            text = self._recognize_with_ai(audio)
            
            if text and text.strip(): # type: ignore
                self._update_status(f"âœ… è¯†åˆ«åˆ°æŒ‡ä»¤: {text}")
                return text
            else:
                self._update_status("âš ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆæŒ‡ä»¤")
                return None
                
        except sr.WaitTimeoutError:
            self._update_status("â° ç­‰å¾…æŒ‡ä»¤è¶…æ—¶")
            return None
        except Exception as e:
            self._update_status(f"âŒ æŒ‡ä»¤è¯†åˆ«å¼‚å¸¸: {e}")
            return None

# ä¸ºäº†å…¼å®¹æ€§ï¼Œä¿ç•™åŸæ¥çš„ç±»å
class SpeechRecognizer(AISpeechRecognizer):
    """å…¼å®¹æ€§åˆ«å"""
    pass
