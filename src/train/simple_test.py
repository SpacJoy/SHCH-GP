# -*- coding: utf-8 -*-
"""
ç®€åŒ–çš„è½»é‡çº§ASRæ€§èƒ½æµ‹è¯•
"""

import os
import sys
import time
import speech_recognition as sr
import warnings
import librosa
import numpy as np
import io
import wave

warnings.filterwarnings("ignore")

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

def load_audio_file_robust(audio_file_path):
    """ä½¿ç”¨å¤šç§æ–¹æ³•åŠ è½½éŸ³é¢‘æ–‡ä»¶"""
    try:
        # æ–¹æ³•1: ç›´æ¥ä½¿ç”¨speech_recognition
        recognizer = sr.Recognizer()
        with sr.AudioFile(audio_file_path) as source:
            audio = recognizer.record(source)
        return audio
    except:
        pass
    
    try:
        # æ–¹æ³•2: ä½¿ç”¨librosaåŠ è½½ï¼Œç„¶åè½¬æ¢ä¸ºwavæ ¼å¼
        y, sr_orig = librosa.load(audio_file_path, sr=16000)
        
        # è½¬æ¢ä¸ºPCMæ ¼å¼
        y_int = np.int16(y / np.max(np.abs(y)) * 32767)
          # åˆ›å»ºä¸´æ—¶wavæ–‡ä»¶
        import tempfile
        temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
        temp_file.close()  # å…³é—­æ–‡ä»¶å¥æŸ„ä»¥ä¾¿å…¶ä»–è¿›ç¨‹è®¿é—®
        
        # ä½¿ç”¨waveæ¨¡å—å†™å…¥æ ‡å‡†wavæ ¼å¼
        with wave.open(temp_file.name, 'wb') as wav_file:
            wav_file.setnchannels(1)  # å•å£°é“
            wav_file.setsampwidth(2)  # 16ä½
            wav_file.setframerate(16000)  # 16kHz
            wav_file.writeframes(y_int.tobytes())
        
        # é‡æ–°åŠ è½½
        recognizer = sr.Recognizer()
        with sr.AudioFile(temp_file.name) as source:
            audio = recognizer.record(source)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_file.name)
        return audio
    except Exception as e:
        print(f"æ— æ³•åŠ è½½éŸ³é¢‘æ–‡ä»¶: {e}")
        return None

def test_light_asr_basic():
    """åŸºç¡€ASRæµ‹è¯•"""
    try:
        from train.model_integration import LightASREngine
        
        print("ğŸ” åˆå§‹åŒ–è½»é‡çº§ASRå¼•æ“...")
        start_time = time.time()
        engine = LightASREngine()
        load_time = time.time() - start_time
        print(f"ğŸ“Š å¼•æ“åˆå§‹åŒ–æ—¶é—´: {load_time:.3f}ç§’")
        
        if not engine.is_available():
            print("âŒ è½»é‡çº§ASRä¸å¯ç”¨")
            return
        
        print("âœ… è½»é‡çº§ASRå¼•æ“å¯ç”¨")
        
        # è·å–å¼•æ“çŠ¶æ€
        status = engine.get_model_info()
        print(f"ğŸ“Š æ¨¡å‹çŠ¶æ€: {status}")
        
        # æµ‹è¯•éŸ³é¢‘æ–‡ä»¶æ¨ç†
        test_audio_dir = "src/train/res/smart_home_dataset/audio"
        if os.path.exists(test_audio_dir):
            print(f"ğŸµ æµ‹è¯•éŸ³é¢‘ç›®å½•: {test_audio_dir}")
            
            # è·å–ç¬¬ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶è¿›è¡Œæµ‹è¯•
            test_files = [f for f in os.listdir(test_audio_dir) if f.endswith('.wav')]
            
            if test_files:
                test_file = os.path.join(test_audio_dir, test_files[0])
                print(f"ğŸ¯ æµ‹è¯•æ–‡ä»¶: {test_file}")
                
                try:
                    audio = load_audio_file_robust(test_file)
                    if audio is None:
                        print("âŒ æ— æ³•åŠ è½½éŸ³é¢‘æ–‡ä»¶")
                        return
                    
                    print("ğŸš€ å¼€å§‹æ¨ç†...")
                    start_time = time.time()
                    result = engine.recognize(audio)
                    inference_time = time.time() - start_time
                    
                    print(f"ğŸ“Š æ¨ç†æ—¶é—´: {inference_time:.3f}ç§’")
                    print(f"ğŸ¯ è¯†åˆ«ç»“æœ: {result}")
                    
                except Exception as e:
                    print(f"âŒ æ¨ç†å¤±è´¥: {e}")
            else:
                print("âŒ æœªæ‰¾åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶")
        else:
            print("âŒ æµ‹è¯•éŸ³é¢‘ç›®å½•ä¸å­˜åœ¨")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

def test_enhanced_asr():
    """æµ‹è¯•å¢å¼ºçš„ASRç³»ç»Ÿ"""
    try:
        from train.model_integration import EnhancedAISpeechRecognizer
        
        print("ğŸ” åˆå§‹åŒ–å¢å¼ºè¯­éŸ³è¯†åˆ«å™¨...")
        
        def status_callback(message):
            print(f"[Status] {message}")
        
        enhanced_asr = EnhancedAISpeechRecognizer(
            status_callback=status_callback,
            use_light_asr=True
        )
        
        # è·å–å¼•æ“çŠ¶æ€
        status = enhanced_asr.get_engine_status()
        print(f"ğŸ“Š å¼•æ“çŠ¶æ€:")
        for key, value in status.items():
            print(f"  - {key}: {value}")
        
        # æ£€æŸ¥éº¦å…‹é£
        if enhanced_asr.is_microphone_available():
            print("âœ… éº¦å…‹é£å¯ç”¨")
        else:
            print("âš ï¸ éº¦å…‹é£ä¸å¯ç”¨")
            
    except Exception as e:
        print(f"âŒ å¢å¼ºASRæµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ å¼€å§‹è½»é‡çº§ASRåŸºç¡€æ€§èƒ½æµ‹è¯•")
    print("=" * 50)
    
    # åŸºç¡€æµ‹è¯•
    test_light_asr_basic()
    
    print("-" * 30)
    
    # å¢å¼ºASRæµ‹è¯•
    test_enhanced_asr()
    
    print("=" * 50)
    print("âœ… æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    main()
