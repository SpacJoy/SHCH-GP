# -*- coding: utf-8 -*-
"""
è½»é‡çº§è¯­éŸ³è¯†åˆ«æ¨¡å‹è®­ç»ƒè„šæœ¬
ç”¨äºè®­ç»ƒä¸“é—¨é’ˆå¯¹æ™ºèƒ½å®¶å±…æ§åˆ¶çš„è¯­éŸ³è¯†åˆ«æ¨¡å‹
"""

import os
import sys
import argparse
import numpy as np
import torch
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from train.model import (
    LightASRModel, 
    LightASRTrainer, 
    LightASRInference,
    SmartHomeVocab,
    create_demo_model,
    test_inference
)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è½»é‡çº§è¯­éŸ³è¯†åˆ«æ¨¡å‹è®­ç»ƒ')
    
    parser.add_argument('--mode', type=str, default='demo', 
                       choices=['demo', 'train', 'test', 'inference'],
                       help='è¿è¡Œæ¨¡å¼: demo(æ¼”ç¤º), train(è®­ç»ƒ), test(æµ‹è¯•), inference(æ¨ç†)')
    
    parser.add_argument('--epochs', type=int, default=20,
                       help='è®­ç»ƒè½®æ•° (é»˜è®¤: 20)')
    
    parser.add_argument('--batch_size', type=int, default=8,
                       help='æ‰¹æ¬¡å¤§å° (é»˜è®¤: 8)')
    
    parser.add_argument('--learning_rate', type=float, default=1e-3,
                       help='å­¦ä¹ ç‡ (é»˜è®¤: 1e-3)')
    
    parser.add_argument('--hidden_dim', type=int, default=128,
                       help='éšè—å±‚ç»´åº¦ (é»˜è®¤: 128)')
    
    parser.add_argument('--num_layers', type=int, default=1,
                       help='RNNå±‚æ•° (é»˜è®¤: 1)')
    
    parser.add_argument('--model_path', type=str, default=None,
                       help='æ¨¡å‹è·¯å¾„ (ç”¨äºåŠ è½½æˆ–ä¿å­˜)')
    
    parser.add_argument('--audio_file', type=str, default=None,
                       help='éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (ç”¨äºæ¨ç†æ¨¡å¼)')
    
    parser.add_argument('--save_name', type=str, default='light_asr_model.pth',
                       help='ä¿å­˜æ¨¡å‹çš„æ–‡ä»¶å')
    
    args = parser.parse_args()
    
    print("ğŸ  æ™ºèƒ½å®¶å±…è½»é‡çº§è¯­éŸ³è¯†åˆ«æ¨¡å‹è®­ç»ƒå·¥å…·")
    print("=" * 60)
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")
    print(f"è®¾å¤‡: {'GPU' if torch.cuda.is_available() else 'CPU'}")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    try:
        if args.mode == 'demo':
            # æ¼”ç¤ºæ¨¡å¼ - åˆ›å»ºå¹¶è®­ç»ƒå°å‹æ¨¡å‹
            print("ğŸ¯ è¿è¡Œæ¼”ç¤ºæ¨¡å¼...")
            model, trainer = create_demo_model()
            test_inference()
            
        elif args.mode == 'train':
            # è®­ç»ƒæ¨¡å¼ - è‡ªå®šä¹‰å‚æ•°è®­ç»ƒ
            print("ğŸš€ å¼€å§‹è‡ªå®šä¹‰è®­ç»ƒ...")
            
            vocab = SmartHomeVocab()
            model = LightASRModel(
                vocab_size=vocab.vocab_size,
                num_classes=50,
                hidden_dim=args.hidden_dim,
                num_layers=args.num_layers
            )
            
            trainer = LightASRTrainer(model, learning_rate=args.learning_rate)
            
            history = trainer.train(
                num_epochs=args.epochs,
                batch_size=args.batch_size
            )
            
            # ä¿å­˜æ¨¡å‹
            trainer.save_model(args.save_name)
            
            print(f"\nğŸ“Š è®­ç»ƒå®Œæˆ!")
            print(f"æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {history['train_acc'][-1]:.4f}")
            print(f"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {history['val_acc'][-1]:.4f}")
            
        elif args.mode == 'test':
            # æµ‹è¯•æ¨¡å¼ - æµ‹è¯•ç°æœ‰æ¨¡å‹
            print("ğŸ§ª æµ‹è¯•æ¨¡å¼...")
            
            if args.model_path and os.path.exists(args.model_path):
                inference = LightASRInference(args.model_path)
                print(f"âœ… å·²åŠ è½½æ¨¡å‹: {args.model_path}")
            else:
                print("âš ï¸ æœªæŒ‡å®šæ¨¡å‹è·¯å¾„æˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨æœªè®­ç»ƒæ¨¡å‹")
                inference = LightASRInference()
            
            # è¿è¡Œæµ‹è¯•
            result = test_inference()
            
        elif args.mode == 'inference':
            # æ¨ç†æ¨¡å¼ - å¯¹æŒ‡å®šéŸ³é¢‘æ–‡ä»¶è¿›è¡Œæ¨ç†
            print("ğŸ” æ¨ç†æ¨¡å¼...")
            
            if not args.audio_file:
                print("âŒ æ¨ç†æ¨¡å¼éœ€è¦æŒ‡å®šéŸ³é¢‘æ–‡ä»¶è·¯å¾„ (--audio_file)")
                return
            
            if not os.path.exists(args.audio_file):
                print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.audio_file}")
                return
            
            # åŠ è½½æ¨¡å‹
            if args.model_path and os.path.exists(args.model_path):
                inference = LightASRInference(args.model_path)
                print(f"âœ… å·²åŠ è½½æ¨¡å‹: {args.model_path}")
            else:
                print("âš ï¸ æœªæŒ‡å®šæ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
                default_model = os.path.join(
                    os.path.dirname(__file__), 'model', 'light_asr_demo.pth'
                )
                if os.path.exists(default_model):
                    inference = LightASRInference(default_model)
                else:
                    inference = LightASRInference()
            
            # è¿›è¡Œæ¨ç†
            print(f"ğŸ¤ åˆ†æéŸ³é¢‘æ–‡ä»¶: {args.audio_file}")
            result = inference.predict_from_file(args.audio_file)
            
            print(f"\nğŸ“Š æ¨ç†ç»“æœ:")
            print(f"åˆ†ç±»é¢„æµ‹: {result['class_prediction']}")
            print(f"åˆ†ç±»ç½®ä¿¡åº¦: {result['class_confidence']:.4f}")
            print(f"ç‰¹å¾ç»´åº¦: {result['features'].shape}")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nâœ… ç¨‹åºæ‰§è¡Œå®Œæˆ")

def show_model_info():
    """æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯"""
    print("\nğŸ“‹ æ¨¡å‹æ¶æ„ä¿¡æ¯:")
    print("=" * 40)
    
    vocab = SmartHomeVocab()
    model = LightASRModel(vocab_size=vocab.vocab_size)
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"è¯æ±‡è¡¨å¤§å°: {vocab.vocab_size}")
    print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"æ¨¡å‹å¤§å°: ~{total_params * 4 / 1024 / 1024:.2f} MB")
    
    print(f"\nğŸ¯ æ”¯æŒçš„æ™ºèƒ½å®¶å±…æŒ‡ä»¤ç±»å‹:")
    for i, (command, _) in enumerate(vocab.command_patterns):
        print(f"  {i+1}. {command}")

def benchmark_model():
    """æ¨¡å‹æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("\nâš¡ æ¨¡å‹æ€§èƒ½åŸºå‡†æµ‹è¯•:")
    print("=" * 40)
    
    vocab = SmartHomeVocab()
    model = LightASRModel(vocab_size=vocab.vocab_size, hidden_dim=128)
    
    # æµ‹è¯•æ¨ç†é€Ÿåº¦
    import time
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 1
    seq_length = 100
    feature_dim = 80
    
    test_input = torch.randn(batch_size, 1, feature_dim, seq_length)
    
    # é¢„çƒ­
    with torch.no_grad():
        for _ in range(10):
            _ = model(test_input)
    
    # è®¡æ—¶æµ‹è¯•
    num_iterations = 100
    start_time = time.time()
    
    with torch.no_grad():
        for _ in range(num_iterations):
            _ = model(test_input)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_iterations
    
    print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_time*1000:.2f} ms")
    print(f"æ¨ç†é€Ÿåº¦: {1/avg_time:.1f} FPS")
    print(f"å†…å­˜ä½¿ç”¨: ~{torch.cuda.memory_allocated() / 1024 / 1024:.2f} MB" if torch.cuda.is_available() else "CPUæ¨¡å¼")

if __name__ == "__main__":
    if len(sys.argv) == 1:
        # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        print("ğŸ  æ™ºèƒ½å®¶å±…è½»é‡çº§è¯­éŸ³è¯†åˆ«æ¨¡å‹")
        print("=" * 50)
        print("\nğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print("python train_model.py --mode demo                    # è¿è¡Œæ¼”ç¤º")
        print("python train_model.py --mode train --epochs 50      # è‡ªå®šä¹‰è®­ç»ƒ")
        print("python train_model.py --mode test                   # æµ‹è¯•æ¨¡å‹")
        print("python train_model.py --mode inference --audio_file audio.wav  # æ¨ç†")
        print("\nğŸ”§ å¯é€‰å‚æ•°:")
        print("--epochs        è®­ç»ƒè½®æ•° (é»˜è®¤: 20)")
        print("--batch_size    æ‰¹æ¬¡å¤§å° (é»˜è®¤: 8)")
        print("--learning_rate å­¦ä¹ ç‡ (é»˜è®¤: 1e-3)")
        print("--hidden_dim    éšè—å±‚ç»´åº¦ (é»˜è®¤: 128)")
        print("--num_layers    RNNå±‚æ•° (é»˜è®¤: 1)")
        print("--model_path    æ¨¡å‹è·¯å¾„")
        print("--save_name     ä¿å­˜æ–‡ä»¶å")
        
        show_model_info()
        benchmark_model()
        
        print("\nğŸ’¡ å¿«é€Ÿå¼€å§‹: python train_model.py --mode demo")
    else:
        main()
