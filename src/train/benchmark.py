# -*- coding: utf-8 -*-
"""
è½»é‡çº§ASRæ€§èƒ½åŸºå‡†æµ‹è¯•
æµ‹è¯•æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„æ€§èƒ½è¡¨ç°
"""

import os
import sys
import time
import numpy as np
import torch
import psutil
import threading
from typing import Dict, List, Optional, Tuple
import tempfile
import wave
import speech_recognition as sr
import warnings
warnings.filterwarnings("ignore")

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from train.model import LightASRInference, AudioFeatureExtractor
from train.model_integration import LightASREngine, EnhancedAISpeechRecognizer

class ASRBenchmark:
    """ASRæ€§èƒ½åŸºå‡†æµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åŸºå‡†æµ‹è¯•å™¨"""
        self.light_asr = LightASREngine()
        self.results = {}
        self.recognizer = sr.Recognizer()
        
    def test_model_loading_time(self) -> float:
        """æµ‹è¯•æ¨¡å‹åŠ è½½æ—¶é—´"""
        print("ğŸ” æµ‹è¯•æ¨¡å‹åŠ è½½æ—¶é—´...")
        
        start_time = time.time()
        engine = LightASREngine()
        if engine.is_available():
            engine.load_model()
        load_time = time.time() - start_time
        
        print(f"ğŸ“Š æ¨¡å‹åŠ è½½æ—¶é—´: {load_time:.3f}ç§’")
        return load_time    
    def test_inference_speed(self, num_samples: int = 20) -> Dict[str, float]:
        """æµ‹è¯•æ¨ç†é€Ÿåº¦"""
        print(f"ğŸš€ æµ‹è¯•æ¨ç†é€Ÿåº¦ (æ ·æœ¬æ•°: {num_samples})...")
        
        if not self.light_asr.is_available():
            print("âŒ è½»é‡çº§ASRä¸å¯ç”¨")
            return {}
        
        # ä½¿ç”¨ç°æœ‰çš„æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
        test_audio_dir = "src/train/res/smart_home_dataset/audio"
        test_files = []
        
        if os.path.exists(test_audio_dir):
            # æ”¶é›†ç°æœ‰çš„éŸ³é¢‘æ–‡ä»¶
            for file in os.listdir(test_audio_dir):
                if file.endswith('.wav'):
                    test_files.append(os.path.join(test_audio_dir, file))
            
            # å¦‚æœæ–‡ä»¶ä¸å¤Ÿï¼Œé‡å¤ä½¿ç”¨
            while len(test_files) < num_samples:
                test_files.extend(test_files[:min(len(test_files), num_samples - len(test_files))])
            
            test_files = test_files[:num_samples]
        else:
            print("âŒ æ‰¾ä¸åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶")
            return {}
        
        # æµ‹è¯•æ¨ç†æ—¶é—´
        inference_times = []
        memory_usage = []
        
        for audio_file in test_files:
            # è®°å½•å†…å­˜ä½¿ç”¨
            process = psutil.Process()
            memory_before = process.memory_info().rss / 1024 / 1024  # MB
            
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶ä¸ºsr.AudioData
            try:
                with sr.AudioFile(audio_file) as source:
                    audio = self.recognizer.record(source)
                
                # æµ‹è¯•æ¨ç†
                start_time = time.time()
                result = self.light_asr.recognize(audio)
                inference_time = time.time() - start_time
                inference_times.append(inference_time)
                
                memory_after = process.memory_info().rss / 1024 / 1024  # MB
                memory_usage.append(memory_after - memory_before)
                
            except Exception as e:
                print(f"âš ï¸ æ¨ç†å¤±è´¥: {e}")
                continue
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if inference_times:
            results = {
                'avg_inference_time': np.mean(inference_times),
                'min_inference_time': np.min(inference_times),
                'max_inference_time': np.max(inference_times),
                'std_inference_time': np.std(inference_times),
                'avg_memory_usage': np.mean(memory_usage),
                'total_samples': len(inference_times)
            }
            
            print(f"ğŸ“Š å¹³å‡æ¨ç†æ—¶é—´: {results['avg_inference_time']:.3f}ç§’")
            print(f"ğŸ“Š æœ€å¿«æ¨ç†æ—¶é—´: {results['min_inference_time']:.3f}ç§’")
            print(f"ğŸ“Š æœ€æ…¢æ¨ç†æ—¶é—´: {results['max_inference_time']:.3f}ç§’")
            print(f"ğŸ“Š å¹³å‡å†…å­˜å¢é‡: {results['avg_memory_usage']:.2f}MB")
            
            return results
        
        return {}
    
    def test_concurrent_inference(self, num_threads: int = 4, samples_per_thread: int = 5) -> Dict[str, float]:
        """æµ‹è¯•å¹¶å‘æ¨ç†æ€§èƒ½"""
        print(f"ğŸ”„ æµ‹è¯•å¹¶å‘æ¨ç† ({num_threads}çº¿ç¨‹ï¼Œæ¯çº¿ç¨‹{samples_per_thread}æ ·æœ¬)...")
        
        if not self.light_asr.is_available():
            print("âŒ è½»é‡çº§ASRä¸å¯ç”¨")
            return {}
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        self.data_generator.set_output_dir(tempfile.mkdtemp())
        test_file = self.data_generator.generate_sample(
            text="å…³é—­å§å®¤çš„ç¯", 
            save_file=True,
            filename="concurrent_test.wav"
        )
        
        if not test_file:
            print("âŒ æ— æ³•ç”Ÿæˆæµ‹è¯•éŸ³é¢‘")
            return {}
        
        # å¹¶å‘æµ‹è¯•
        results = []
        threads = []
        
        def worker_thread(thread_id: int):
            """å·¥ä½œçº¿ç¨‹"""
            thread_times = []
            engine = LightASREngine()  # æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹çš„å¼•æ“
            
            for i in range(samples_per_thread):
                start_time = time.time()
                try:
                    result = engine.recognize_file(test_file)
                    inference_time = time.time() - start_time
                    thread_times.append(inference_time)
                except Exception as e:
                    print(f"âš ï¸ çº¿ç¨‹{thread_id}æ¨ç†å¤±è´¥: {e}")
            
            results.extend(thread_times)
        
        # å¯åŠ¨çº¿ç¨‹
        start_time = time.time()
        for i in range(num_threads):
            thread = threading.Thread(target=worker_thread, args=(i,))
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…å®Œæˆ
        for thread in threads:
            thread.join()
        
        total_time = time.time() - start_time
        
        if results:
            concurrent_results = {
                'total_time': total_time,
                'avg_inference_time': np.mean(results),
                'throughput': len(results) / total_time,  # samples per second
                'num_threads': num_threads,
                'total_samples': len(results)
            }
            
            print(f"ğŸ“Š æ€»è€—æ—¶: {concurrent_results['total_time']:.3f}ç§’")
            print(f"ğŸ“Š å¹³å‡æ¨ç†æ—¶é—´: {concurrent_results['avg_inference_time']:.3f}ç§’")
            print(f"ğŸ“Š ååé‡: {concurrent_results['throughput']:.2f} æ ·æœ¬/ç§’")
            
            return concurrent_results
        
        return {}
    
    def test_accuracy_on_generated_data(self, num_samples: int = 50) -> Dict[str, float]:
        """åœ¨ç”Ÿæˆæ•°æ®ä¸Šæµ‹è¯•å‡†ç¡®ç‡"""
        print(f"ğŸ¯ æµ‹è¯•ç”Ÿæˆæ•°æ®å‡†ç¡®ç‡ (æ ·æœ¬æ•°: {num_samples})...")
        
        if not self.light_asr.is_available():
            print("âŒ è½»é‡çº§ASRä¸å¯ç”¨")
            return {}
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®é›†
        self.data_generator.set_output_dir(tempfile.mkdtemp())
        test_commands = [
            "æ‰“å¼€å®¢å…çš„ç¯", "å…³é—­å§å®¤çš„ç¯", "è°ƒé«˜ç©ºè°ƒæ¸©åº¦",
            "æ’­æ”¾éŸ³ä¹", "æš‚åœæ’­æ”¾", "è°ƒèŠ‚éŸ³é‡", 
            "æ‰“å¼€ç”µè§†", "å…³é—­ç”µè§†", "åˆ‡æ¢é¢‘é“"
        ]
        
        correct_predictions = 0
        total_predictions = 0
        confidence_scores = []
        
        for i in range(num_samples):
            # éšæœºé€‰æ‹©æŒ‡ä»¤
            command = test_commands[i % len(test_commands)]
            
            # ç”ŸæˆéŸ³é¢‘
            audio_file = self.data_generator.generate_sample(
                text=command,
                save_file=True,
                filename=f"accuracy_test_{i}.wav"
            )
            
            if not audio_file:
                continue
            
            # è¯†åˆ«
            try:
                result = self.light_asr.recognize_file(audio_file)
                total_predictions += 1
                
                if result and command in result:
                    correct_predictions += 1
                
                # å¦‚æœæœ‰ç½®ä¿¡åº¦ä¿¡æ¯ï¼Œè®°å½•ä¸‹æ¥
                if hasattr(self.light_asr, 'last_confidence'):
                    confidence_scores.append(self.light_asr.last_confidence)
                    
            except Exception as e:
                print(f"âš ï¸ è¯†åˆ«å¤±è´¥: {e}")
                continue
        
        if total_predictions > 0:
            accuracy = correct_predictions / total_predictions
            avg_confidence = np.mean(confidence_scores) if confidence_scores else 0
            
            accuracy_results = {
                'accuracy': accuracy,
                'correct_predictions': correct_predictions,
                'total_predictions': total_predictions,
                'avg_confidence': avg_confidence
            }
            
            print(f"ğŸ“Š å‡†ç¡®ç‡: {accuracy:.2%}")
            print(f"ğŸ“Š æ­£ç¡®é¢„æµ‹: {correct_predictions}/{total_predictions}")
            print(f"ğŸ“Š å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
            
            return accuracy_results
        
        return {}
    
    def test_resource_usage(self, duration_seconds: int = 60) -> Dict[str, float]:
        """æµ‹è¯•èµ„æºä½¿ç”¨æƒ…å†µ"""
        print(f"ğŸ’» æµ‹è¯•èµ„æºä½¿ç”¨ (æŒç»­{duration_seconds}ç§’)...")
        
        if not self.light_asr.is_available():
            print("âŒ è½»é‡çº§ASRä¸å¯ç”¨")
            return {}
        
        # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
        self.data_generator.set_output_dir(tempfile.mkdtemp())
        test_file = self.data_generator.generate_sample(
            text="æµ‹è¯•èµ„æºä½¿ç”¨",
            save_file=True,
            filename="resource_test.wav"
        )
        
        if not test_file:
            print("âŒ æ— æ³•ç”Ÿæˆæµ‹è¯•éŸ³é¢‘")
            return {}
        
        # ç›‘æ§èµ„æºä½¿ç”¨
        process = psutil.Process()
        cpu_percentages = []
        memory_usage = []
        
        start_time = time.time()
        
        while time.time() - start_time < duration_seconds:
            # æ‰§è¡Œæ¨ç†
            try:
                self.light_asr.recognize_file(test_file)
            except:
                pass
            
            # è®°å½•èµ„æºä½¿ç”¨
            cpu_percent = process.cpu_percent()
            memory_mb = process.memory_info().rss / 1024 / 1024
            
            cpu_percentages.append(cpu_percent)
            memory_usage.append(memory_mb)
            
            time.sleep(0.5)  # æ¯0.5ç§’é‡‡æ ·ä¸€æ¬¡
        
        if cpu_percentages and memory_usage:
            resource_results = {
                'avg_cpu_percent': np.mean(cpu_percentages),
                'max_cpu_percent': np.max(cpu_percentages),
                'avg_memory_mb': np.mean(memory_usage),
                'max_memory_mb': np.max(memory_usage),
                'duration': duration_seconds
            }
            
            print(f"ğŸ“Š å¹³å‡CPUä½¿ç”¨ç‡: {resource_results['avg_cpu_percent']:.1f}%")
            print(f"ğŸ“Š æœ€é«˜CPUä½¿ç”¨ç‡: {resource_results['max_cpu_percent']:.1f}%")
            print(f"ğŸ“Š å¹³å‡å†…å­˜ä½¿ç”¨: {resource_results['avg_memory_mb']:.1f}MB")
            print(f"ğŸ“Š æœ€é«˜å†…å­˜ä½¿ç”¨: {resource_results['max_memory_mb']:.1f}MB")
            
            return resource_results
        
        return {}
    
    def run_full_benchmark(self) -> Dict[str, any]:
        """è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•"""
        print("ğŸ å¼€å§‹å®Œæ•´åŸºå‡†æµ‹è¯•...")
        print("=" * 60)
        
        full_results = {}
        
        # 1. æ¨¡å‹åŠ è½½æ—¶é—´
        try:
            full_results['loading_time'] = self.test_model_loading_time()
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
            full_results['loading_time'] = None
        
        print("-" * 40)
        
        # 2. æ¨ç†é€Ÿåº¦
        try:
            full_results['inference_speed'] = self.test_inference_speed(20)
        except Exception as e:
            print(f"âŒ æ¨ç†é€Ÿåº¦æµ‹è¯•å¤±è´¥: {e}")
            full_results['inference_speed'] = None
        
        print("-" * 40)
        
        # 3. å¹¶å‘æ€§èƒ½
        try:
            full_results['concurrent_performance'] = self.test_concurrent_inference(4, 5)
        except Exception as e:
            print(f"âŒ å¹¶å‘æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            full_results['concurrent_performance'] = None
        
        print("-" * 40)
        
        # 4. å‡†ç¡®ç‡æµ‹è¯•
        try:
            full_results['accuracy'] = self.test_accuracy_on_generated_data(30)
        except Exception as e:
            print(f"âŒ å‡†ç¡®ç‡æµ‹è¯•å¤±è´¥: {e}")
            full_results['accuracy'] = None
        
        print("-" * 40)
        
        # 5. èµ„æºä½¿ç”¨
        try:
            full_results['resource_usage'] = self.test_resource_usage(30)
        except Exception as e:
            print(f"âŒ èµ„æºä½¿ç”¨æµ‹è¯•å¤±è´¥: {e}")
            full_results['resource_usage'] = None
        
        print("=" * 60)
        print("âœ… åŸºå‡†æµ‹è¯•å®Œæˆ")
        
        return full_results
    
    def generate_report(self, results: Dict[str, any]) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report = []
        report.append("# è½»é‡çº§ASRæ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
        report.append(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # æ¨¡å‹åŠ è½½æ—¶é—´
        if results.get('loading_time'):
            report.append("## æ¨¡å‹åŠ è½½æ€§èƒ½")
            report.append(f"- åŠ è½½æ—¶é—´: {results['loading_time']:.3f}ç§’")
            report.append("")
        
        # æ¨ç†é€Ÿåº¦
        if results.get('inference_speed'):
            speed = results['inference_speed']
            report.append("## æ¨ç†é€Ÿåº¦æ€§èƒ½")
            report.append(f"- å¹³å‡æ¨ç†æ—¶é—´: {speed['avg_inference_time']:.3f}ç§’")
            report.append(f"- æœ€å¿«æ¨ç†æ—¶é—´: {speed['min_inference_time']:.3f}ç§’")
            report.append(f"- æœ€æ…¢æ¨ç†æ—¶é—´: {speed['max_inference_time']:.3f}ç§’")
            report.append(f"- æ ‡å‡†å·®: {speed['std_inference_time']:.3f}ç§’")
            report.append(f"- å¹³å‡å†…å­˜å¢é‡: {speed['avg_memory_usage']:.2f}MB")
            report.append("")
        
        # å¹¶å‘æ€§èƒ½
        if results.get('concurrent_performance'):
            concurrent = results['concurrent_performance']
            report.append("## å¹¶å‘æ€§èƒ½")
            report.append(f"- çº¿ç¨‹æ•°: {concurrent['num_threads']}")
            report.append(f"- æ€»æ ·æœ¬æ•°: {concurrent['total_samples']}")
            report.append(f"- æ€»è€—æ—¶: {concurrent['total_time']:.3f}ç§’")
            report.append(f"- ååé‡: {concurrent['throughput']:.2f} æ ·æœ¬/ç§’")
            report.append("")
        
        # å‡†ç¡®ç‡
        if results.get('accuracy'):
            accuracy = results['accuracy']
            report.append("## å‡†ç¡®ç‡æ€§èƒ½")
            report.append(f"- å‡†ç¡®ç‡: {accuracy['accuracy']:.2%}")
            report.append(f"- æ­£ç¡®é¢„æµ‹: {accuracy['correct_predictions']}/{accuracy['total_predictions']}")
            if accuracy['avg_confidence'] > 0:
                report.append(f"- å¹³å‡ç½®ä¿¡åº¦: {accuracy['avg_confidence']:.3f}")
            report.append("")
        
        # èµ„æºä½¿ç”¨
        if results.get('resource_usage'):
            resource = results['resource_usage']
            report.append("## èµ„æºä½¿ç”¨")
            report.append(f"- å¹³å‡CPUä½¿ç”¨ç‡: {resource['avg_cpu_percent']:.1f}%")
            report.append(f"- æœ€é«˜CPUä½¿ç”¨ç‡: {resource['max_cpu_percent']:.1f}%")
            report.append(f"- å¹³å‡å†…å­˜ä½¿ç”¨: {resource['avg_memory_mb']:.1f}MB")
            report.append(f"- æœ€é«˜å†…å­˜ä½¿ç”¨: {resource['max_memory_mb']:.1f}MB")
            report.append("")
        
        report.append("---")
        report.append("*æŠ¥å‘Šç”±è½»é‡çº§ASRåŸºå‡†æµ‹è¯•å·¥å…·è‡ªåŠ¨ç”Ÿæˆ*")
        
        return "\n".join(report)

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è½»é‡çº§ASRæ€§èƒ½åŸºå‡†æµ‹è¯•")
    parser.add_argument('--test', choices=['loading', 'speed', 'concurrent', 'accuracy', 'resource', 'all'],
                       default='all', help='æµ‹è¯•ç±»å‹')
    parser.add_argument('--samples', type=int, default=20, help='æµ‹è¯•æ ·æœ¬æ•°')
    parser.add_argument('--threads', type=int, default=4, help='å¹¶å‘çº¿ç¨‹æ•°')
    parser.add_argument('--duration', type=int, default=30, help='èµ„æºæµ‹è¯•æŒç»­æ—¶é—´(ç§’)')
    parser.add_argument('--report', type=str, help='ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶')
    
    args = parser.parse_args()
    
    benchmark = ASRBenchmark()
    
    if args.test == 'all':
        results = benchmark.run_full_benchmark()
        
        # ç”ŸæˆæŠ¥å‘Š
        if args.report:
            report = benchmark.generate_report(results)
            with open(args.report, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.report}")
    
    elif args.test == 'loading':
        benchmark.test_model_loading_time()
    elif args.test == 'speed':
        benchmark.test_inference_speed(args.samples)
    elif args.test == 'concurrent':
        benchmark.test_concurrent_inference(args.threads, args.samples)
    elif args.test == 'accuracy':
        benchmark.test_accuracy_on_generated_data(args.samples)
    elif args.test == 'resource':
        benchmark.test_resource_usage(args.duration)

if __name__ == "__main__":
    main()
