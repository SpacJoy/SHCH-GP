# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„æ™ºèƒ½å®¶å±…è¯­éŸ³æ•°æ®é›†ç”Ÿæˆå™¨
ç”Ÿæˆæ›´å¤šæ ·åŒ–å’ŒçœŸå®çš„è®­ç»ƒæ•°æ®
"""

import os
import sys
import numpy as np
import librosa
import soundfile as sf
from typing import List, Dict, Tuple, Optional
import json
import random
import argparse
from dataclasses import dataclass
import warnings
warnings.filterwarnings("ignore")

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

@dataclass
class VoiceProfile:
    """è¯­éŸ³ç‰¹å¾é…ç½®"""
    pitch_shift: float = 0.0  # éŸ³è°ƒåç§»ï¼ˆåŠéŸ³ï¼‰
    speed_change: float = 1.0  # è¯­é€Ÿå˜åŒ–
    volume_gain: float = 1.0  # éŸ³é‡å¢ç›Š
    background_noise: float = 0.0  # èƒŒæ™¯å™ªå£°çº§åˆ«
    voice_type: str = "neutral"  # å£°éŸ³ç±»å‹

class EnhancedDatasetGenerator:
    """å¢å¼ºçš„æ•°æ®é›†ç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "src/train/res/enhanced_dataset"):
        self.output_dir = output_dir
        self.sample_rate = 16000
        self.target_duration = 2.0  # ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, "audio"), exist_ok=True)
        
        # æ‰©å±•çš„æ™ºèƒ½å®¶å±…æŒ‡ä»¤é›†
        self.command_categories = {
            "ç¯å…‰æ§åˆ¶": [
                "æ‰“å¼€{room}çš„ç¯", "å…³é—­{room}çš„ç¯", "è°ƒäº®{room}çš„ç¯", "è°ƒæš—{room}çš„ç¯",
                "è®¾ç½®{room}ç¯å…‰äº®åº¦ä¸º{level}", "åˆ‡æ¢{room}çš„ç¯", "å¼€å¯{room}å¤œç¯æ¨¡å¼",
                "å…³é—­æ‰€æœ‰ç¯å…‰", "æ‰“å¼€å…¨éƒ¨ç¯", "ç¯å…‰åœºæ™¯åˆ‡æ¢", "å¼€å¯é˜…è¯»æ¨¡å¼"
            ],
            "ç©ºè°ƒæ§åˆ¶": [
                "æ‰“å¼€ç©ºè°ƒ", "å…³é—­ç©ºè°ƒ", "è°ƒé«˜æ¸©åº¦", "è°ƒä½æ¸©åº¦", "è®¾ç½®æ¸©åº¦ä¸º{temp}åº¦",
                "ç©ºè°ƒåˆ¶å†·æ¨¡å¼", "ç©ºè°ƒåˆ¶çƒ­æ¨¡å¼", "ç©ºè°ƒé™¤æ¹¿æ¨¡å¼", "ç©ºè°ƒé£é€Ÿè°ƒèŠ‚",
                "æ‰“å¼€{room}ç©ºè°ƒ", "å…³é—­{room}ç©ºè°ƒ", "ç©ºè°ƒå®šæ—¶å¼€å¯", "ç©ºè°ƒå®šæ—¶å…³é—­"
            ],
            "ç”µè§†æ§åˆ¶": [
                "æ‰“å¼€ç”µè§†", "å…³é—­ç”µè§†", "åˆ‡æ¢é¢‘é“", "è°ƒé«˜éŸ³é‡", "è°ƒä½éŸ³é‡",
                "ç”µè§†é™éŸ³", "å–æ¶ˆé™éŸ³", "æ’­æ”¾{channel}", "æœç´¢{content}",
                "å›åˆ°ä¸»é¡µ", "æ‰“å¼€åº”ç”¨", "ç”µè§†å¾…æœº"
            ],
            "éŸ³ä¹æ§åˆ¶": [
                "æ’­æ”¾éŸ³ä¹", "æš‚åœéŸ³ä¹", "åœæ­¢æ’­æ”¾", "ä¸‹ä¸€é¦–", "ä¸Šä¸€é¦–",
                "è°ƒèŠ‚éŸ³é‡", "æ’­æ”¾{song}", "æ’­æ”¾{artist}çš„æ­Œ",
                "æ’­æ”¾å¤å…¸éŸ³ä¹", "æ’­æ”¾æµè¡ŒéŸ³ä¹", "éŸ³ä¹å¾ªç¯æ’­æ”¾", "éšæœºæ’­æ”¾"
            ],
            "çª—å¸˜æ§åˆ¶": [
                "æ‰“å¼€çª—å¸˜", "å…³é—­çª—å¸˜", "æ‹‰å¼€{room}çª—å¸˜", "æ‹‰ä¸Š{room}çª—å¸˜",
                "çª—å¸˜åŠå¼€", "çª—å¸˜å…¨å¼€", "çª—å¸˜å…¨å…³", "è‡ªåŠ¨çª—å¸˜æ¨¡å¼"
            ],
            "é£æ‰‡æ§åˆ¶": [
                "æ‰“å¼€é£æ‰‡", "å…³é—­é£æ‰‡", "é£æ‰‡è°ƒé€Ÿ", "é£æ‰‡æ‘†å¤´",
                "é£æ‰‡å®šæ—¶", "æ‰“å¼€{room}é£æ‰‡", "å…³é—­{room}é£æ‰‡",
                "é£æ‰‡ä¸€æ¡£", "é£æ‰‡äºŒæ¡£", "é£æ‰‡ä¸‰æ¡£"
            ],
            "å®‰å…¨æ§åˆ¶": [
                "å¼€å¯å®‰é˜²æ¨¡å¼", "å…³é—­å®‰é˜²æ¨¡å¼", "æŸ¥çœ‹ç›‘æ§", "é”é—¨", "å¼€é—¨",
                "å®‰é˜²å¸ƒé˜²", "å®‰é˜²æ’¤é˜²", "æŠ¥è­¦å™¨å¼€å¯", "æŠ¥è­¦å™¨å…³é—­"
            ],
            "ç¯å¢ƒæ§åˆ¶": [
                "æŸ¥çœ‹æ¸©åº¦", "æŸ¥çœ‹æ¹¿åº¦", "ç©ºæ°”å‡€åŒ–å™¨å¼€å¯", "ç©ºæ°”å‡€åŒ–å™¨å…³é—­",
                "åŠ æ¹¿å™¨å¼€å¯", "åŠ æ¹¿å™¨å…³é—­", "æ£€æµ‹ç©ºæ°”è´¨é‡", "å¼€å¯æ–°é£ç³»ç»Ÿ"
            ]
        }
        
        # æˆ¿é—´ç±»å‹
        self.rooms = ["å®¢å…", "å§å®¤", "å¨æˆ¿", "ä¹¦æˆ¿", "é¤å…", "ä¸»å§", "æ¬¡å§", "å„¿ç«¥æˆ¿"]
        
        # å‚æ•°æ›¿æ¢é€‰é¡¹
        self.replacements = {
            "temp": ["20", "22", "24", "26", "28"],
            "level": ["50%", "80%", "æœ€äº®", "æœ€æš—", "ä¸­ç­‰"],
            "channel": ["æ–°é—»é¢‘é“", "ç”µå½±é¢‘é“", "ç»¼è‰ºé¢‘é“", "ä½“è‚²é¢‘é“"],
            "content": ["ç”µå½±", "æ–°é—»", "ç»¼è‰º", "éŸ³ä¹"],
            "song": ["å‘¨æ°ä¼¦çš„æ­Œ", "æµè¡Œæ­Œæ›²", "è½»éŸ³ä¹", "å¤å…¸éŸ³ä¹"],
            "artist": ["å‘¨æ°ä¼¦", "é‚“ç´«æ£‹", "æ—ä¿Šæ°", "ç‹è²"]
        }
        
        # è¯­éŸ³å˜åŒ–é…ç½®
        self.voice_profiles = [
            VoiceProfile(pitch_shift=0, speed_change=1.0, voice_type="æ ‡å‡†ç”·å£°"),
            VoiceProfile(pitch_shift=2, speed_change=0.95, voice_type="æ ‡å‡†å¥³å£°"),
            VoiceProfile(pitch_shift=-1, speed_change=1.1, voice_type="ä½æ²‰ç”·å£°"),
            VoiceProfile(pitch_shift=3, speed_change=0.9, voice_type="æ¸…è„†å¥³å£°"),
            VoiceProfile(pitch_shift=1, speed_change=1.05, voice_type="å¹´è½»ç”·å£°"),
            VoiceProfile(pitch_shift=0, speed_change=0.85, voice_type="ç¼“æ…¢è¯­éŸ³"),
            VoiceProfile(pitch_shift=0, speed_change=1.15, voice_type="å¿«é€Ÿè¯­éŸ³"),
        ]
    
    def generate_all_commands(self) -> List[str]:
        """ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„æŒ‡ä»¤ç»„åˆ"""
        all_commands = []
        
        for category, templates in self.command_categories.items():
            for template in templates:
                if "{room}" in template:
                    for room in self.rooms:
                        command = template.replace("{room}", room)
                        all_commands.extend(self._replace_other_params(command))
                else:
                    all_commands.extend(self._replace_other_params(template))
        
        return list(set(all_commands))  # å»é‡
    
    def _replace_other_params(self, command: str) -> List[str]:
        """æ›¿æ¢æŒ‡ä»¤ä¸­çš„å…¶ä»–å‚æ•°"""
        if any(param in command for param in ["{temp}", "{level}", "{channel}", "{content}", "{song}", "{artist}"]):
            results = []
            
            # æ›¿æ¢æ‰€æœ‰å‚æ•°
            for key, values in self.replacements.items():
                param_placeholder = "{" + key + "}"
                if param_placeholder in command:
                    for value in values:
                        results.append(command.replace(param_placeholder, value))
                    return results
            
            return [command]  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å‚æ•°ï¼Œè¿”å›åŸå‘½ä»¤
        else:
            return [command]
    
    def create_synthetic_audio(self, text: str, voice_profile: VoiceProfile) -> np.ndarray:
        """åˆ›å»ºåˆæˆéŸ³é¢‘ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„éŸ³é¢‘åˆæˆå‡½æ•°
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ‚¨å¯èƒ½éœ€è¦ä½¿ç”¨æ›´é«˜çº§çš„TTSå¼•æ“
        
        # åŸºç¡€éŸ³é¢‘ç”Ÿæˆï¼ˆåŸºäºæ–‡æœ¬é•¿åº¦å’Œç‰¹å¾ï¼‰
        duration = max(len(text) * 0.08, 1.0)  # åŸºäºæ–‡æœ¬é•¿åº¦ä¼°ç®—æ—¶é•¿
        duration = min(duration, self.target_duration)
        
        # ç”ŸæˆåŸºç¡€æ³¢å½¢
        t = np.linspace(0, duration, int(duration * self.sample_rate))
        
        # åˆ›å»ºå¤šé¢‘ç‡ç»„åˆçš„éŸ³é¢‘ä¿¡å·ï¼ˆæ¨¡æ‹Ÿè¯­éŸ³ï¼‰
        audio = np.zeros_like(t)
        
        # åŸºç¡€é¢‘ç‡ï¼ˆæ¨¡æ‹Ÿè¯­éŸ³çš„åŸºé¢‘ï¼‰
        f0 = 150 * (2 ** (voice_profile.pitch_shift / 12.0))  # éŸ³è°ƒåç§»
        
        # æ·»åŠ å¤šä¸ªè°æ³¢åˆ†é‡
        for harmonic in range(1, 6):
            frequency = f0 * harmonic
            amplitude = 1.0 / harmonic  # éšè°æ³¢æ¬¡æ•°è¡°å‡
            
            # æ·»åŠ ä¸€äº›éšæœºæ€§æ¨¡æ‹Ÿè¯­éŸ³å˜åŒ–
            freq_modulation = 1 + 0.05 * np.sin(2 * np.pi * 3 * t)  # è½»å¾®é¢‘ç‡è°ƒåˆ¶
            audio += amplitude * np.sin(2 * np.pi * frequency * freq_modulation * t)
        
        # æ·»åŠ è¯­éŸ³åŒ…ç»œï¼ˆéŸ³é‡å˜åŒ–ï¼‰
        envelope = np.exp(-3 * np.abs(t - duration/2) / duration)  # ä¸­é—´å¤§ï¼Œä¸¤è¾¹å°
        audio = audio * envelope
        
        # åº”ç”¨è¯­é€Ÿå˜åŒ–
        if voice_profile.speed_change != 1.0:
            original_length = len(audio)
            new_length = int(original_length / voice_profile.speed_change)
            audio = np.interp(np.linspace(0, original_length-1, new_length), 
                             np.arange(original_length), audio)
        
        # åº”ç”¨éŸ³é‡å¢ç›Š
        audio = audio * voice_profile.volume_gain
        
        # æ·»åŠ èƒŒæ™¯å™ªå£°
        if voice_profile.background_noise > 0:
            noise = np.random.normal(0, voice_profile.background_noise, len(audio))
            audio = audio + noise
        
        # æ ‡å‡†åŒ–éŸ³é¢‘
        if np.max(np.abs(audio)) > 0:
            audio = audio / np.max(np.abs(audio)) * 0.8
        
        # ç¡®ä¿ç›®æ ‡æ—¶é•¿
        target_samples = int(self.target_duration * self.sample_rate)
        if len(audio) < target_samples:
            # å¡«å……é™éŸ³
            padding = target_samples - len(audio)
            audio = np.pad(audio, (0, padding), mode='constant')
        elif len(audio) > target_samples:
            # æˆªæ–­
            audio = audio[:target_samples]
        
        return audio
    
    def generate_enhanced_dataset(self, 
                                 num_samples_per_command: int = 3,
                                 max_total_samples: int = 1000) -> Dict:
        """ç”Ÿæˆå¢å¼ºçš„æ•°æ®é›†"""
        print("ğŸš€ å¼€å§‹ç”Ÿæˆå¢å¼ºæ•°æ®é›†...")
        
        # è·å–æ‰€æœ‰æŒ‡ä»¤
        all_commands = self.generate_all_commands()
        print(f"ğŸ“ æ€»å…± {len(all_commands)} ä¸ªä¸åŒçš„æŒ‡ä»¤")
        
        # æ§åˆ¶æ€»æ ·æœ¬æ•°
        if len(all_commands) * num_samples_per_command > max_total_samples:
            num_samples_per_command = max(1, max_total_samples // len(all_commands))
            print(f"âš¡ è°ƒæ•´æ¯ä¸ªæŒ‡ä»¤çš„æ ·æœ¬æ•°ä¸º {num_samples_per_command} ä»¥æ§åˆ¶æ€»é‡")
        
        # ç”Ÿæˆæ•°æ®
        dataset_info = {
            "total_samples": 0,
            "commands": [],
            "categories": {},
            "voice_profiles": [profile.voice_type for profile in self.voice_profiles],
            "generation_time": "",
            "sample_rate": self.sample_rate,
            "target_duration": self.target_duration
        }
        
        sample_index = 0
        
        for command in all_commands:
            if sample_index >= max_total_samples:
                break
                
            for sample_num in range(num_samples_per_command):
                if sample_index >= max_total_samples:
                    break
                
                # éšæœºé€‰æ‹©è¯­éŸ³ç‰¹å¾
                voice_profile = random.choice(self.voice_profiles)
                
                # ç”ŸæˆéŸ³é¢‘
                try:
                    audio = self.create_synthetic_audio(command, voice_profile)
                    
                    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                    filename = f"enhanced_sample_{sample_index:06d}.wav"
                    filepath = os.path.join(self.output_dir, "audio", filename)
                    sf.write(filepath, audio, self.sample_rate)
                    
                    # è®°å½•ä¿¡æ¯
                    sample_info = {
                        "filename": filename,
                        "text": command,
                        "voice_profile": voice_profile.voice_type,
                        "category": self._get_command_category(command),
                        "duration": self.target_duration
                    }
                    
                    dataset_info["commands"].append(sample_info)
                    
                    sample_index += 1
                    
                    if sample_index % 50 == 0:
                        print(f"ğŸ“Š å·²ç”Ÿæˆ {sample_index} ä¸ªæ ·æœ¬...")
                        
                except Exception as e:
                    print(f"âš ï¸ ç”Ÿæˆæ ·æœ¬å¤±è´¥: {e}")
                    continue
        
        # ç»Ÿè®¡ç±»åˆ«ä¿¡æ¯
        for sample in dataset_info["commands"]:
            category = sample["category"]
            if category not in dataset_info["categories"]:
                dataset_info["categories"][category] = 0
            dataset_info["categories"][category] += 1
        
        dataset_info["total_samples"] = len(dataset_info["commands"])
        
        # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
        info_file = os.path.join(self.output_dir, "dataset_info.json")
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(dataset_info, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {dataset_info['total_samples']}")
        print(f"ğŸ“‚ ä¿å­˜ä½ç½®: {self.output_dir}")
        
        return dataset_info
    
    def _get_command_category(self, command: str) -> str:
        """è·å–æŒ‡ä»¤æ‰€å±ç±»åˆ«"""
        for category, templates in self.command_categories.items():
            for template in templates:
                # ç®€åŒ–çš„æ¨¡æ¿åŒ¹é…
                template_words = template.replace("{room}", "").replace("{temp}", "").replace("{level}", "").replace("{channel}", "").replace("{content}", "").replace("{song}", "").replace("{artist}", "").split()
                if all(word in command for word in template_words if len(word) > 1):
                    return category
        return "å…¶ä»–"
    
    def analyze_dataset(self) -> Dict:
        """åˆ†æç°æœ‰æ•°æ®é›†"""
        info_file = os.path.join(self.output_dir, "dataset_info.json")
        
        if not os.path.exists(info_file):
            print("âŒ æœªæ‰¾åˆ°æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶")
            return {}
        
        with open(info_file, 'r', encoding='utf-8') as f:
            dataset_info = json.load(f)
        
        print("ğŸ“Š æ•°æ®é›†åˆ†ææŠ¥å‘Š")
        print("=" * 40)
        print(f"æ€»æ ·æœ¬æ•°: {dataset_info['total_samples']}")
        print(f"é‡‡æ ·ç‡: {dataset_info['sample_rate']} Hz")
        print(f"ç›®æ ‡æ—¶é•¿: {dataset_info['target_duration']} ç§’")
        
        print("\nç±»åˆ«åˆ†å¸ƒ:")
        for category, count in dataset_info["categories"].items():
            percentage = count / dataset_info["total_samples"] * 100
            print(f"  {category}: {count} ä¸ªæ ·æœ¬ ({percentage:.1f}%)")
        
        print(f"\nè¯­éŸ³ç±»å‹: {', '.join(dataset_info['voice_profiles'])}")
        
        return dataset_info
    
    def create_training_splits(self, train_ratio: float = 0.8) -> Dict:
        """åˆ›å»ºè®­ç»ƒ/éªŒè¯æ•°æ®é›†åˆ†å‰²"""
        info_file = os.path.join(self.output_dir, "dataset_info.json")
        
        if not os.path.exists(info_file):
            print("âŒ æœªæ‰¾åˆ°æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶")
            return {}
        
        with open(info_file, 'r', encoding='utf-8') as f:
            dataset_info = json.load(f)
        
        commands = dataset_info["commands"]
        random.shuffle(commands)
        
        split_index = int(len(commands) * train_ratio)
        train_commands = commands[:split_index]
        val_commands = commands[split_index:]
        
        # ä¿å­˜åˆ†å‰²ä¿¡æ¯
        splits = {
            "train": train_commands,
            "validation": val_commands,
            "train_count": len(train_commands),
            "val_count": len(val_commands),
            "train_ratio": train_ratio
        }
        
        splits_file = os.path.join(self.output_dir, "dataset_splits.json")
        with open(splits_file, 'w', encoding='utf-8') as f:
            json.dump(splits, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š æ•°æ®é›†åˆ†å‰²å®Œæˆ:")
        print(f"  è®­ç»ƒé›†: {len(train_commands)} ä¸ªæ ·æœ¬ ({train_ratio*100:.1f}%)")
        print(f"  éªŒè¯é›†: {len(val_commands)} ä¸ªæ ·æœ¬ ({(1-train_ratio)*100:.1f}%)")
        
        return splits

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¢å¼ºçš„æ™ºèƒ½å®¶å±…è¯­éŸ³æ•°æ®é›†ç”Ÿæˆå™¨")
    parser.add_argument('--output_dir', type=str, default="src/train/res/enhanced_dataset",
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--samples_per_command', type=int, default=3,
                       help='æ¯ä¸ªæŒ‡ä»¤çš„æ ·æœ¬æ•°')
    parser.add_argument('--max_samples', type=int, default=1000,
                       help='æœ€å¤§æ ·æœ¬æ€»æ•°')
    parser.add_argument('--action', choices=['generate', 'analyze', 'split'], 
                       default='generate', help='æ“ä½œç±»å‹')
    parser.add_argument('--train_ratio', type=float, default=0.8,
                       help='è®­ç»ƒé›†æ¯”ä¾‹')
    
    args = parser.parse_args()
    
    generator = EnhancedDatasetGenerator(args.output_dir)
    
    if args.action == 'generate':
        generator.generate_enhanced_dataset(
            num_samples_per_command=args.samples_per_command,
            max_total_samples=args.max_samples
        )
    elif args.action == 'analyze':
        generator.analyze_dataset()
    elif args.action == 'split':
        generator.create_training_splits(args.train_ratio)

if __name__ == "__main__":
    main()
